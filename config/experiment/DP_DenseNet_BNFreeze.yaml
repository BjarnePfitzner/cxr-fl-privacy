# @package _global_

experiment_name: FL_DenseNet_BNFreeze
save_model: False

training:
  T: 15
  q: 0.1
  B: 16
  weighted_avg: False
  optimizer: SGD
  lr: 0.005
  reduce_lr_rounds: 3
  max_client_selections: 7

data:
  clients: all

dp:
  enabled: True
  epsilon: 10
  max_delta: 1e-2
  S: 1.0
  z: 0.1

model:
  net: DenseNet121
  freeze_layers: batch_norm

hydra:
  sweeper:
    params:
      training.B:
        - 8
        - 16
        - 64
      training.optimizer:
        - SGD
        - SGDM
        - Adam
      training.lr:
        - 0.01
        - 0.005
        - 0.001
      training.reduce_lr_rounds:
        - 3
        - 100
      training.weighted_avg:
        - True
        - False
      training.q:
        - 0.1
        - 0.25
        - 0.5
        - 1.0
      #seed:
      #  - 0
      #  - 1
      #  - 2